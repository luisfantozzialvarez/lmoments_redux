rm(list=ls())
setwd("~/Documents/GitHub/lmoments_redux/application/")
julia_path = '/Applications/Julia-1.9.app/Contents/Resources/julia/bin'
source("specifications_application.R")
source("../methods/estimation.R")
source("../methods/selection.R")
source("../methods/semiparametric_model.R")
load('intermmediate_alt.RData')
load('intermmediate_alt.RDS')
osition = sapply(grid.test, function(x) c(ifelse(is.null(x[[1]]), Inf, x[[1]]$est$value), ifelse(is.null(x[[2]]), Inf, x[[2]]$est$value)))
line_min = which.min(apply(position,2 ,min))
col_min = which.min(position[,line_min])
#This will be the mixture model
model.tail = grid.test[[line_min]][[col_min]]
prev.tail <-model.tail
#We will now apply a continuously-updating procedure to improve the weighting matrix estimator
list.tail <- list(model.tail)
maxit=10
for(j in 1:maxit)
list.tail[[j+1]] <- tryCatch({lmoment.semiparametric(early, late, y_pos, x_pos, w_pos, s_pos, par_guess.2,
L, grid_inv = 1000,
lmoment.analytic = lmoment.analytic.gev.mix, quantile.func =  quantile.function.gev.mix,
density.function = density.function.gev.mix,
model = model.twoside, control = list( "maxit"=1000), first.step = list.tail[[j]]$est)}, error = function(e) NULL)
model.tail = list.tail[[2]]
#model.tail= list.tail[[1+which.min(sapply(list.tail[2:(maxit+1)], function(x) x$est$value))]]
#cue=c(-33.7839512,80.8420467,0.3996655,0.6520455,-13.8492711,36.1123750,1.5394240)
#3. Generating results
grid_x = seq(min(late$expenses),max(late$expenses),by=0.1)
dens <- function(par) density.function.gpd(grid_x, par)
jacob_gpd = ad_jacobian(dens,ts$ss$par)
grid_e = seq(min(model$model$res_oos),to=max(model$model$res_oos),0.1)
dens_e <- function(par) density.function.gev.mix(grid_e,par)
jacob_e = jacob.density.function.gev.mix(grid_e,model.tail$est$par)
#Results
#Setting seed again
set.seed(123)
#3.1 Raw data
#Overidentifying restrictions test
pvalue = 1 - pchisq(ts$ss$value*nrow(late), L-length(ts$ss$par))
Nsims = 5000
vcov.gpd = ts$vcov/ts$N
sim_crit = jacob_gpd%*%t(chol(vcov.gpd))%*%matrix(rnorm(length(ts$ss$par)*Nsims),length(ts$ss$par))
diag_center = sqrt(diag(jacob_gpd%*%vcov.gpd%*%t(jacob_gpd)))
sim_crit = sim_crit/diag_center
vlh = apply(sim_crit,2, function(x)max(abs(x)))
lower_upper = cbind(dens(ts$ss$par) - diag_center*quantile(vlh,0.95), dens(ts$ss$par) + diag_center*quantile(vlh,0.95))
curve.f <- function(x) density.function.gpd(x, ts$ss$par)
pdf('expenses.pdf', height = 5, width=5)
hist(late$expenses,freq=F,breaks = seq(min(10*ceiling(late$expenses)%/%10),max(11*floor(late$expenses)%/%10),10), xlab = 'Expenditures (BRL)',
main = 'Weekly expenditure')
polygon(c(grid_x, rev(grid_x)), c(lower_upper[,1], rev(lower_upper[,2])), col = "#0000FF50",border=NA)
curve(curve.f, from = min(late$expenses), to = max(late$expenses), col = 'blue', add=T)
dev.off()
#3.2 Model errors
#Overidentifying restrictions test
pvalue = 1 - pchisq(model.tail$est$value*model.tail$N, L-length(model.tail$est$par))
vcov.gev = model.tail$vcov/model.tail$N
sim_crit = jacob_e%*%t(chol(vcov.gev))%*%matrix(rnorm(length(model.tail$est$par)*Nsims),nrow=length(model.tail$est$par))
diag_center = sqrt(diag(jacob_e%*%vcov.gev%*%t(jacob_e)))
sim_crit = sim_crit/diag_center
vlh = apply(sim_crit,2, function(x)max(abs(x)))
lower_upper = cbind(dens_e(model.tail$est$par) - diag_center*quantile(vlh,0.95), dens_e(model.tail$est$par) + diag_center*quantile(vlh,0.95))
curve.f <- function(x) density.function.gev.mix(x, model.tail$est$par)
pdf('res.pdf', height = 5, width=5)
hist(model$model$res_oos,freq=F,breaks = seq(min(10*ceiling(model$model$res_oos)%/%10),max(11*floor(model$model$res_oos)%/%10),10), xlab = 'Expenditures (BRL)',
main =  expression(Delta~hat(e)[it]))
polygon(c(grid_e, rev(grid_e)), c(lower_upper[,1], rev(lower_upper[,2])), col = "#0000FF50",border=NA)
curve(curve.f,min(model$model$res_oos),max(model$model$res_oos),col = 'blue', add=T)
dev.off()
#99 Percent CI
write.csv(cbind(model.tail$est$par, model.tail$est$par - qnorm(1-0.01/2)*sqrt(diag(vcov.gev)),model.tail$est$par +  qnorm(1-0.01/2)*sqrt(diag(vcov.gev))),'coefs.csv')
save.image('final.RData')
model.tail$est
model.tail= list.tail[[1+which.min(sapply(list.tail[2:(maxit+1)], function(x) x$est$value))]]
#3. Generating results
grid_x = seq(min(late$expenses),max(late$expenses),by=0.1)
dens <- function(par) density.function.gpd(grid_x, par)
jacob_gpd = ad_jacobian(dens,ts$ss$par)
grid_e = seq(min(model$model$res_oos),to=max(model$model$res_oos),0.1)
dens_e <- function(par) density.function.gev.mix(grid_e,par)
jacob_e = jacob.density.function.gev.mix(grid_e,model.tail$est$par)
#Results
#Setting seed again
set.seed(123)
#3.1 Raw data
#Overidentifying restrictions test
pvalue = 1 - pchisq(ts$ss$value*nrow(late), L-length(ts$ss$par))
Nsims = 5000
vcov.gpd = ts$vcov/ts$N
sim_crit = jacob_gpd%*%t(chol(vcov.gpd))%*%matrix(rnorm(length(ts$ss$par)*Nsims),length(ts$ss$par))
diag_center = sqrt(diag(jacob_gpd%*%vcov.gpd%*%t(jacob_gpd)))
sim_crit = sim_crit/diag_center
vlh = apply(sim_crit,2, function(x)max(abs(x)))
lower_upper = cbind(dens(ts$ss$par) - diag_center*quantile(vlh,0.95), dens(ts$ss$par) + diag_center*quantile(vlh,0.95))
curve.f <- function(x) density.function.gpd(x, ts$ss$par)
pdf('expenses.pdf', height = 5, width=5)
hist(late$expenses,freq=F,breaks = seq(min(10*ceiling(late$expenses)%/%10),max(11*floor(late$expenses)%/%10),10), xlab = 'Expenditures (BRL)',
main = 'Weekly expenditure')
polygon(c(grid_x, rev(grid_x)), c(lower_upper[,1], rev(lower_upper[,2])), col = "#0000FF50",border=NA)
curve(curve.f, from = min(late$expenses), to = max(late$expenses), col = 'blue', add=T)
dev.off()
#3.2 Model errors
#Overidentifying restrictions test
pvalue = 1 - pchisq(model.tail$est$value*model.tail$N, L-length(model.tail$est$par))
vcov.gev = model.tail$vcov/model.tail$N
sim_crit = jacob_e%*%t(chol(vcov.gev))%*%matrix(rnorm(length(model.tail$est$par)*Nsims),nrow=length(model.tail$est$par))
diag_center = sqrt(diag(jacob_e%*%vcov.gev%*%t(jacob_e)))
sim_crit = sim_crit/diag_center
vlh = apply(sim_crit,2, function(x)max(abs(x)))
lower_upper = cbind(dens_e(model.tail$est$par) - diag_center*quantile(vlh,0.95), dens_e(model.tail$est$par) + diag_center*quantile(vlh,0.95))
curve.f <- function(x) density.function.gev.mix(x, model.tail$est$par)
pdf('res.pdf', height = 5, width=5)
hist(model$model$res_oos,freq=F,breaks = seq(min(10*ceiling(model$model$res_oos)%/%10),max(11*floor(model$model$res_oos)%/%10),10), xlab = 'Expenditures (BRL)',
main =  expression(Delta~hat(e)[it]))
polygon(c(grid_e, rev(grid_e)), c(lower_upper[,1], rev(lower_upper[,2])), col = "#0000FF50",border=NA)
curve(curve.f,min(model$model$res_oos),max(model$model$res_oos),col = 'blue', add=T)
dev.off()
#99 Percent CI
write.csv(cbind(model.tail$est$par, model.tail$est$par - qnorm(1-0.01/2)*sqrt(diag(vcov.gev)),model.tail$est$par +  qnorm(1-0.01/2)*sqrt(diag(vcov.gev))),'coefs.csv')
1+which.min(sapply(list.tail[2:(maxit+1)], function(x) x$est$value))
sapply(list.tail[2:(maxit+1)], function(x) x$est$value))
sapply(list.tail[2:(maxit+1)], function(x) x$est$value)
intermmediate_alt <- readRDS("~/Documents/GitHub/lmoments_redux/application/intermmediate_alt.RDS")
load('intermmediate_alt.RDS')
position = sapply(grid.test, function(x) c(ifelse(is.null(x[[1]]), Inf, x[[1]]$est$value), ifelse(is.null(x[[2]]), Inf, x[[2]]$est$value)))
line_min = which.min(apply(position,2 ,min))
col_min = which.min(position[,line_min])
#This will be the mixture model
model.tail = grid.test[[line_min]][[col_min]]
model.tail$est
position = sapply(grid.test, function(x) c(ifelse(is.null(x[[1]]), Inf, x[[1]]$est$value), ifelse(is.null(x[[2]]), Inf, x[[2]]$est$value)))
line_min = which.min(apply(position,2 ,min))
col_min = which.min(position[,line_min])
#This will be the mixture model
model.tail = grid.test[[line_min]][[col_min]]
prev.tail <-model.tail
#We will now apply a continuously-updating procedure to improve the weighting matrix estimator
list.tail <- list(model.tail)
maxit=30
for(j in 1:20)
list.tail[[j+1]] <- tryCatch({lmoment.semiparametric(early, late, y_pos, x_pos, w_pos, s_pos, par_guess.2,
L, grid_inv = 1000,
lmoment.analytic = lmoment.analytic.gev.mix, quantile.func =  quantile.function.gev.mix,
density.function = density.function.gev.mix,
model = model.twoside, control = list( "maxit"=1000), first.step = list.tail[[j]]$est)}, error = function(e) NULL)
length(list.tail)
